{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dbd5369e",
      "metadata": {
        "id": "dbd5369e"
      },
      "source": [
        "# ESC-50 Environmental Sound Classification\n",
        "**Course:** AIN413 - Machine Learning for Healthcare  \n",
        "**Project Title:** Vibration-Based Feedback Devices for Environmental Sound Recognition  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85623360",
      "metadata": {
        "id": "85623360"
      },
      "source": [
        "## 1. Setup and Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-e5izmDqr9DE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e5izmDqr9DE",
        "outputId": "93e435e7-bb37-4971-965b-0c448d525f88"
      },
      "outputs": [],
      "source": [
        "!pip install noisereduce\n",
        "!pip install tensorflow.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rNgN3RBwqKID",
      "metadata": {
        "id": "rNgN3RBwqKID"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "import librosa\n",
        "import librosa.display\n",
        "import noisereduce as nr\n",
        "import seaborn as sns\n",
        "from IPython.display import Audio, display\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from scipy.stats import loguniform,randint,uniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from IPython.display import Audio, display\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PzEwf5VFnF5G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "PzEwf5VFnF5G",
        "outputId": "c926faf0-96d6-4ca4-c72e-a74e837a5f4d"
      },
      "outputs": [],
      "source": [
        "# Upload kaggle.json which includes Kaggle API to download from kaggle directly\n",
        "\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!pip install -q kaggle librosa scikit-learn matplotlib seaborn tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4mU2cAibnKjV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mU2cAibnKjV",
        "outputId": "000a3c76-5965-4bd5-b447-eb30ca275130"
      },
      "outputs": [],
      "source": [
        "# Download and unzip dataset\n",
        "!kaggle datasets download -d mmoreaux/environmental-sound-classification-50\n",
        "!unzip -q environmental-sound-classification-50.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uF3awaI1nMiC",
      "metadata": {
        "id": "uF3awaI1nMiC"
      },
      "outputs": [],
      "source": [
        "meta = pd.read_csv('/content/esc50.csv')\n",
        "DATA_PATH = '/content/audio/audio'\n",
        "TEST_DIR = '/content/wav_sound'\n",
        "\n",
        "!unzip -q /content/wav_sound.zip\n",
        "\n",
        "selected_categories = [\n",
        "    \"dog\", \"thunderstorm\", \"crying_baby\",\n",
        "    \"door_wood_knock\", \"siren\", \"car_horn\"\n",
        "]\n",
        "\n",
        "filtered_meta = meta[meta[\"category\"].isin(selected_categories)].reset_index(drop=True)\n",
        "filtered_meta = filtered_meta.drop(columns=[\"esc10\", \"src_file\", \"take\", \"fold\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe5deb8",
      "metadata": {
        "id": "2fe5deb8"
      },
      "source": [
        "## 2. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s7oUtJB8oCv1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "s7oUtJB8oCv1",
        "outputId": "f2255ff9-0d88-4906-9cab-3ec58535e4fa"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=filtered_meta, x='category', order=filtered_meta['category'].value_counts().index)\n",
        "plt.title('Class Distributions')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1x1CYqw-oRP8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "1x1CYqw-oRP8",
        "outputId": "4c1d31a3-04ee-4608-c4a7-c531b609023d"
      },
      "outputs": [],
      "source": [
        "durations = []\n",
        "for f in filtered_meta['filename']:\n",
        "    y, sr = librosa.load(f\"{DATA_PATH}/{f}\", sr=None)\n",
        "    durations.append(len(y)/sr)\n",
        "\n",
        "plt.hist(durations, bins=20)\n",
        "plt.xlabel(\"Duration (seconds)\")\n",
        "plt.title(\"Distribution of Audio Lengths\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rqJZh_eLOzl_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "rqJZh_eLOzl_",
        "outputId": "924104d7-db5c-439b-fa65-fcd83f26d74f"
      },
      "outputs": [],
      "source": [
        "energies = [np.mean(librosa.feature.rms(y=librosa.load(f\"{DATA_PATH}/{f}\", sr=None)[0])) for f in filtered_meta['filename']]\n",
        "sns.histplot(energies, bins=20)\n",
        "plt.title(\"Root Mean Square Energy Distribution\")\n",
        "plt.xlabel(\"Energy\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mouM61l0oTjm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "id": "mouM61l0oTjm",
        "outputId": "a7d23562-94a1-4e83-dca9-8624b6b2afe4"
      },
      "outputs": [],
      "source": [
        "# Get all files\n",
        "all_files = [f for f in os.listdir(DATA_PATH) if f.endswith(\".wav\")]\n",
        "selected_files = random.sample(all_files, 4)  # Choose many as you want\n",
        "# Visualize\n",
        "plt.figure(figsize=(15, 8))\n",
        "for i, file in enumerate(selected_files):\n",
        "    file_path = os.path.join(DATA_PATH, file)\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Waveform\n",
        "    plt.subplot(2, len(selected_files), i + 1)\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    plt.title(f'Waveform\\n{file}')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Spectrogram\n",
        "    plt.subplot(2, len(selected_files), i + 1 + len(selected_files))\n",
        "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Spectrogram')\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.suptitle(\"Random Sampled ESC-50 Audio Files\", fontsize=16, y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b59c901e",
      "metadata": {
        "id": "b59c901e"
      },
      "source": [
        "## 3. Feature Extraction and Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "coPr1UIqrc2e",
      "metadata": {
        "id": "coPr1UIqrc2e"
      },
      "outputs": [],
      "source": [
        "# This function removes silence, reduces background noise, resamples to 44.1kHz.\n",
        "\n",
        "def adapt_audio(file_path, target_sr=44100):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Noice reduction\n",
        "    try:\n",
        "        import noisereduce as nr\n",
        "        y = nr.reduce_noise(y=y, sr=sr)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Resample\n",
        "    if sr != target_sr:\n",
        "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
        "\n",
        "    return y, target_sr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x-B0bfTkrwI6",
      "metadata": {
        "id": "x-B0bfTkrwI6"
      },
      "outputs": [],
      "source": [
        "# Adds random white noise to the audio signal to simulate background interference.\n",
        "def add_noise(y, noise_level=0.005):\n",
        "    noise = np.random.randn(len(y))  # Generate random noise\n",
        "    return y + noise_level * noise  # Add it to the original signal\n",
        "\n",
        "# Stretches the audio in time (makes it faster or slower).\n",
        "# Useful for data augmentation.\n",
        "def time_stretch(y, rate=1.1):\n",
        "    return librosa.effects.time_stretch(y=y, rate=rate)\n",
        "\n",
        "# Shifts the pitch of the audio without changing its speed.\n",
        "# Also used for data augmentation.\n",
        "def pitch_shift(y, sr, n_steps=2):\n",
        "    return librosa.effects.pitch_shift(y=y, sr=sr, n_steps=n_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DoNutnQMogb_",
      "metadata": {
        "id": "DoNutnQMogb_"
      },
      "outputs": [],
      "source": [
        "# Feature Extraction with Augmentation (MFCC + Delta features)\n",
        "\n",
        "def extract_augmented_mfccs(file_path):\n",
        "    y, sr = adapt_audio(file_path)  # Preprocess the audio: trim, denoise, resample\n",
        "    features = []\n",
        "\n",
        "    # Original audio\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "    delta = librosa.feature.delta(mfcc)\n",
        "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "    combined = np.vstack([mfcc, delta, delta2])\n",
        "    features.append(np.mean(combined.T, axis=0))  # Average over time axis\n",
        "\n",
        "    # Noisy version\n",
        "    y_noise = add_noise(y)\n",
        "    mfcc = librosa.feature.mfcc(y=y_noise, sr=sr, n_mfcc=40)\n",
        "    delta = librosa.feature.delta(mfcc)\n",
        "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "    combined = np.vstack([mfcc, delta, delta2])\n",
        "    features.append(np.mean(combined.T, axis=0))\n",
        "\n",
        "    # Pitch-shifted version\n",
        "    y_pitch = pitch_shift(y, sr=sr)\n",
        "    mfcc = librosa.feature.mfcc(y=y_pitch, sr=sr, n_mfcc=40)\n",
        "    delta = librosa.feature.delta(mfcc)\n",
        "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "    combined = np.vstack([mfcc, delta, delta2])\n",
        "    features.append(np.mean(combined.T, axis=0))\n",
        "\n",
        "    # Time-stretched version\n",
        "    try: # In case any errors happen.\n",
        "        y_stretch = time_stretch(y=y)\n",
        "        mfcc = librosa.feature.mfcc(y=y_stretch, sr=sr, n_mfcc=40)\n",
        "        delta = librosa.feature.delta(mfcc)\n",
        "        delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "        combined = np.vstack([mfcc, delta, delta2])\n",
        "        features.append(np.mean(combined.T, axis=0))\n",
        "    except:\n",
        "        pass  # Skip this augmentation if it fails\n",
        "\n",
        "    return features  # List of 1D feature vectors (one for each variation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0291df79",
      "metadata": {
        "id": "0291df79"
      },
      "source": [
        "## 4. Generating Train Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PA_LHqazovK3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA_LHqazovK3",
        "outputId": "ad26b205-0087-4d14-e7ff-cd8b56ebbc39"
      },
      "outputs": [],
      "source": [
        "# Extracting features from all audio files and prepare labels\n",
        "\n",
        "X_mfcc, y = [], []\n",
        "\n",
        "# Loop through each row\n",
        "for _, row in tqdm(filtered_meta.iterrows(), total=len(filtered_meta)):\n",
        "    # Extract  augmented versions of data\n",
        "    feats = extract_augmented_mfccs(os.path.join(DATA_PATH, row['filename']))\n",
        "\n",
        "    # Add each feature set to the dataset\n",
        "    for feat in feats:\n",
        "        X_mfcc.append(feat)\n",
        "        y.append(row['category'])  # Store the corresponding label\n",
        "\n",
        "# Convert feature list to NumPy array for model input\n",
        "X_mfcc = np.array(X_mfcc)\n",
        "\n",
        "# Convert string labels to integer classes\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zF5QWMPmtRpT",
      "metadata": {
        "id": "zF5QWMPmtRpT"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_mfcc, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97054e7d",
      "metadata": {
        "id": "97054e7d"
      },
      "source": [
        "## 5. Model Training and Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "657acbe3",
      "metadata": {
        "id": "657acbe3"
      },
      "source": [
        "### 5.1 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UkSXgvtxpTYN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkSXgvtxpTYN",
        "outputId": "a673a6f6-20e2-4fcb-f632-b771d6488969"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_dist_rf = {\n",
        "    'n_estimators': randint(20, 100),\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 4],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt'],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "random_search_rf = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist_rf,\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search_rf.fit(X_train, y_train)\n",
        "best_rf = random_search_rf.best_estimator_\n",
        "\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "print(\"Best Parameters:\", random_search_rf.best_params_)\n",
        "print(\"\\nGridSearch Optimized Random Forest Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d2b41b",
      "metadata": {
        "id": "82d2b41b"
      },
      "source": [
        "### 5.2 Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T_5RsjRfpVGC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_5RsjRfpVGC",
        "outputId": "1ec68dbd-dcb4-4f89-b06b-14256d39b5b0"
      },
      "outputs": [],
      "source": [
        "svm = SVC(probability=True)\n",
        "\n",
        "param_dist_svm = {\n",
        "    'C': uniform(0.1, 10),  # regularization\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "random_search_svm = RandomizedSearchCV(\n",
        "    estimator=svm,\n",
        "    param_distributions=param_dist_svm,\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search_svm.fit(X_train, y_train)\n",
        "best_svm = random_search_svm.best_estimator_\n",
        "y_pred_svm = best_svm.predict(X_test)\n",
        "\n",
        "print(\"Best SVM Parameters:\", random_search_svm.best_params_)\n",
        "print(\"\\nOptimized SVM Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=le.classes_, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba297632",
      "metadata": {
        "id": "ba297632"
      },
      "source": [
        "### 5.3 Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IsiwYfibo0tL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsiwYfibo0tL",
        "outputId": "59712f46-75f9-4480-f6bb-bf29d13a2cba"
      },
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(random_state=42, max_iter=300)\n",
        "\n",
        "param_dist_mlp = {\n",
        "    'hidden_layer_sizes': [(64,), (64, 32)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'alpha': loguniform(1e-5, 1e-2),\n",
        "    'solver': ['adam'],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "random_search_mlp = RandomizedSearchCV(\n",
        "    estimator=mlp,\n",
        "    param_distributions=param_dist_mlp,\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search_mlp.fit(X_train, y_train)\n",
        "best_mlp = random_search_mlp.best_estimator_\n",
        "\n",
        "y_pred_mlp = best_mlp.predict(X_test)\n",
        "\n",
        "print(\"Best MLP Parameters:\", random_search_mlp.best_params_)\n",
        "print(\"\\nOptimized MLP Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_mlp, target_names=le.classes_, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qj3n8yX6gqo8",
      "metadata": {
        "id": "Qj3n8yX6gqo8"
      },
      "source": [
        "### 5.4 Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vXyG-HCmgqWT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXyG-HCmgqWT",
        "outputId": "6bfbd17d-bc7b-4e9d-c8b5-23099bd0a977"
      },
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "param_dist_dt = {\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 4],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_features': ['sqrt', None]\n",
        "}\n",
        "\n",
        "random_search_dt = RandomizedSearchCV(\n",
        "    estimator=dt,\n",
        "    param_distributions=param_dist_dt,\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search_dt.fit(X_train, y_train)\n",
        "best_dt = random_search_dt.best_estimator_\n",
        "\n",
        "y_pred_dt = best_dt.predict(X_test)\n",
        "\n",
        "print(\"Best Decision Tree Parameters:\", random_search_dt.best_params_)\n",
        "print(\"\\nOptimized Decision Tree Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_dt, target_names=le.classes_, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ca1c5cd",
      "metadata": {
        "id": "3ca1c5cd"
      },
      "source": [
        "### 5.5 Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ojsBodzaj2Pd",
      "metadata": {
        "id": "ojsBodzaj2Pd"
      },
      "outputs": [],
      "source": [
        "def augment_audio_variants(y, sr):\n",
        "    variants = []\n",
        "\n",
        "    variants.append(y)\n",
        "\n",
        "    # Added random noise\n",
        "    noise = np.random.randn(len(y))\n",
        "    y_noise = y + 0.005 * noise\n",
        "    variants.append(y_noise)\n",
        "\n",
        "    # Pitch shift\n",
        "    variants.append(librosa.effects.pitch_shift(y, sr=sr, n_steps=2))\n",
        "    variants.append(librosa.effects.pitch_shift(y, sr=sr, n_steps=-2))\n",
        "\n",
        "    # Time stretch\n",
        "    try:\n",
        "        variants.append(librosa.effects.time_stretch(y, rate=1.1))\n",
        "        variants.append(librosa.effects.time_stretch(y, rate=0.9))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return variants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ObxY9WWvj3Gi",
      "metadata": {
        "id": "ObxY9WWvj3Gi"
      },
      "outputs": [],
      "source": [
        "def extract_logmel_from_audio(y, sr, n_mels=128, hop_length=512, fix_len=216):\n",
        "\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
        "    log_mel = librosa.power_to_db(mel)\n",
        "    log_mel = librosa.util.fix_length(log_mel, size=fix_len, axis=1)\n",
        "    return log_mel[..., np.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfuSGingj31a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfuSGingj31a",
        "outputId": "2e92fa3a-1e84-4f32-e10b-0c69df98b29b"
      },
      "outputs": [],
      "source": [
        "X_logmel, y = [], []\n",
        "\n",
        "for _, row in tqdm(filtered_meta.iterrows(), total=len(filtered_meta)):\n",
        "    filepath = os.path.join(DATA_PATH, row['filename'])\n",
        "    y_raw, sr = librosa.load(filepath, sr=22050, duration=5)\n",
        "\n",
        "    # Create variants for audios\n",
        "    augmented_audios = augment_audio_variants(y_raw, sr)\n",
        "\n",
        "\n",
        "    for audio in augmented_audios:\n",
        "        logmel = extract_logmel_from_audio(audio, sr)\n",
        "        X_logmel.append(logmel)\n",
        "        y.append(row[\"category\"])\n",
        "\n",
        "\n",
        "X_logmel = np.array(X_logmel)\n",
        "y_encoded = LabelEncoder().fit_transform(y)\n",
        "y_cat = to_categorical(y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "laJX0ukzj03U",
      "metadata": {
        "id": "laJX0ukzj03U"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_logmel, y_cat, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kEpNl4PLkIII",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kEpNl4PLkIII",
        "outputId": "a538855d-80b3-4696-b749-a302fd677df1"
      },
      "outputs": [],
      "source": [
        "# Set num class\n",
        "num_classes = len(np.unique(y_encoded))\n",
        "\n",
        "input_shape = (128, 216, 1)\n",
        "\n",
        "# Model description\n",
        "cnn = Sequential([\n",
        "    Input(shape=input_shape),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "cnn.summary()\n",
        "\n",
        "history = cnn.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "y_pred_cnn = cnn.predict(X_test)\n",
        "y_pred_classes_cnn = np.argmax(y_pred_cnn, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred_classes_cnn, target_names=le.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04d12442",
      "metadata": {
        "id": "04d12442"
      },
      "source": [
        "## 6. Evaluation With Sound Recorded From Real World Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gVNjZwWuEMxl",
      "metadata": {
        "id": "gVNjZwWuEMxl"
      },
      "outputs": [],
      "source": [
        "label_to_text = {\n",
        "    'dog': \"üê∂ Dog barking detected!\",\n",
        "    'thunderstorm': \"üå©Ô∏è Thunderstorm sound detected!\",\n",
        "    'door_wood_knock': \"üö™ Door knocking sound detected!\",\n",
        "    'car_horn': \"üì£ Car horn detected!\",\n",
        "    'crying_baby': \"üë∂ Baby crying detected!\",\n",
        "    'siren': \"üöë Siren sound detected!\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12-nZ52Po6Jb",
      "metadata": {
        "id": "12-nZ52Po6Jb"
      },
      "outputs": [],
      "source": [
        "def predict_test_audio(model, CONFIDENCE_THRESHOLD=0.6):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    match_counter = Counter()\n",
        "    total_counter = Counter()\n",
        "\n",
        "    print(\"\\nüì¢ Prediction and Playback (Top-2 with confidence):\\n\")\n",
        "\n",
        "    for file in sorted(os.listdir(TEST_DIR)):\n",
        "        if file.endswith(\".wav\"):\n",
        "            file_path = os.path.join(TEST_DIR, file)\n",
        "\n",
        "            # Preprocess the audio file\n",
        "            y_test, sr_test = adapt_audio(file_path)\n",
        "            mfcc = librosa.feature.mfcc(y=y_test, sr=sr_test, n_mfcc=40)\n",
        "            delta = librosa.feature.delta(mfcc)\n",
        "            delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "            features = np.vstack([mfcc, delta, delta2])\n",
        "            input_feat = np.mean(features.T, axis=0).reshape(1, -1)\n",
        "\n",
        "            # Predict class probabilities\n",
        "            probs = model.predict_proba(input_feat)[0]\n",
        "            sorted_indices = np.argsort(probs)[::-1]\n",
        "\n",
        "            # Top-2 predictions\n",
        "            top1_idx = sorted_indices[0]\n",
        "            top2_idx = sorted_indices[1]\n",
        "            top1_label = le.inverse_transform([top1_idx])[0]\n",
        "            top2_label = le.inverse_transform([top2_idx])[0]\n",
        "            top1_conf = probs[top1_idx]\n",
        "            top2_conf = probs[top2_idx]\n",
        "\n",
        "            # Try to get true label from filename if possible\n",
        "            true_label = None\n",
        "            for label in le.classes_:\n",
        "                if label in file.lower():\n",
        "                    true_label = label\n",
        "                    break\n",
        "\n",
        "            if true_label:\n",
        "                y_true.append(true_label)\n",
        "                y_pred.append(top1_label)\n",
        "                total_counter[true_label] += 1\n",
        "                if top1_label == true_label:\n",
        "                    match_counter[true_label] += 1\n",
        "\n",
        "            # Display result\n",
        "            if top1_conf >= CONFIDENCE_THRESHOLD:\n",
        "                print(f\"{file}: ‚úÖ {label_to_text.get(top1_label, top1_label)} (Confidence = {top1_conf:.2f})\")\n",
        "            else:\n",
        "                print(f\"{file}: ‚ùì Not confident\\n ‚Ü™ 1. {label_to_text.get(top1_label, top1_label)} ({top1_conf:.2f})\"\n",
        "                      f\"\\n ‚Ü™ 2. {label_to_text.get(top2_label, top2_label)} ({top2_conf:.2f})\")\n",
        "\n",
        "            display(Audio(file_path))\n",
        "\n",
        "    # Accuracy calculation using Counter\n",
        "    total = sum(total_counter.values())\n",
        "    correct = sum(match_counter.values())\n",
        "    accuracy = correct / total if total > 0 else 0.0\n",
        "    print(f\"\\nüìä Accuracy of the Real world scenarios = {accuracy:.2f} ({correct}/{total})\")\n",
        "\n",
        "def predict_test_audio_cnn(model, CONFIDENCE_THRESHOLD=0.6):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    print(\"\\nüì¢ Prediction and Playback:\\n\")\n",
        "\n",
        "    for file in sorted(os.listdir(TEST_DIR)):\n",
        "        if file.endswith(\".wav\"):\n",
        "            file_path = os.path.join(TEST_DIR, file)\n",
        "\n",
        "            # 1. Load and extract log-mel spectrogram\n",
        "            y, sr = librosa.load(file_path, sr=22050, duration=5)\n",
        "            mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "            logmel = librosa.power_to_db(mel)\n",
        "            logmel = librosa.util.fix_length(logmel, size=216, axis=1)\n",
        "\n",
        "            # 2. Reshape for CNN input\n",
        "            input_feat = logmel[np.newaxis, ..., np.newaxis]  # (1, 128, 216, 1)\n",
        "\n",
        "            # 3. Predict\n",
        "            prediction = model.predict(input_feat)\n",
        "            predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "            predicted_label = le.inverse_transform([predicted_index])[0]\n",
        "\n",
        "            # 4. Display prediction\n",
        "            message = label_to_text.get(predicted_label, predicted_label)\n",
        "            print(f\"{file}: {message}\")\n",
        "            display(Audio(file_path))\n",
        "\n",
        "            # 5. Check ground truth from filename\n",
        "            for label in le.classes_:\n",
        "                if label in file.lower():\n",
        "                    total += 1\n",
        "                    if predicted_label == label:\n",
        "                        correct += 1\n",
        "                    break\n",
        "\n",
        "    if total > 0:\n",
        "        accuracy = correct / total\n",
        "        print(f\"\\nüìä Accuracy of the real-world scenarios = {accuracy:.2f} ({correct}/{total})\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è No ground truth labels could be inferred from filenames.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JUDL7chLtZGZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JUDL7chLtZGZ",
        "outputId": "d184c02a-1a14-49eb-d792-081feeea63d0"
      },
      "outputs": [],
      "source": [
        "predict_test_audio(best_mlp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z55hMG06tlmd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z55hMG06tlmd",
        "outputId": "69ec0448-eb76-4c32-a96f-028035e5e39d"
      },
      "outputs": [],
      "source": [
        "predict_test_audio(best_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QP60w71EKGTJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QP60w71EKGTJ",
        "outputId": "a89e9344-5f8f-402f-ab52-ba49b3a9b6b7"
      },
      "outputs": [],
      "source": [
        "predict_test_audio(best_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sSmjPsyuKGoX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sSmjPsyuKGoX",
        "outputId": "ef1fab55-dce0-49e9-bf16-a899132ba394"
      },
      "outputs": [],
      "source": [
        "predict_test_audio(best_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DCOWPqnNvSgb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DCOWPqnNvSgb",
        "outputId": "dfb004fc-62b4-43cc-d219-9152c05d7470"
      },
      "outputs": [],
      "source": [
        "predict_test_audio_cnn(cnn)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
